{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Image Classification with VAE-Generated Hybrid Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "still in progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.adam import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import torchsummary\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the CIFAR100 dataset\n",
    "- For training the CNN, the rotation and horizontal flip will be applied to the training set in order to make the training set more diverse\n",
    "- For training the VAE, it is important to keep the training set simple in order to allow the latent space to learn effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "path = '~/datasets'\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transforms_CNN = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter()\n",
    "])\n",
    "\n",
    "CNN_train = CIFAR100(path, train=True, download=True, transform=transforms_CNN)\n",
    "CNN_test = CIFAR100(path, train=False, download=True, transform=transforms_CNN)\n",
    "\n",
    "CNN_train_dl = DataLoader(CNN_train, batch_size=batch_size, shuffle=True)\n",
    "CNN_test_dl = DataLoader(CNN_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "classes = CNN_train.classes\n",
    "CNN_dataloaders = {'train': CNN_train_dl, 'val': CNN_test_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_VAE = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "VAE_train = CIFAR100(path, train=True, download=True, transform=transforms_VAE)\n",
    "VAE_test = CIFAR100(path, train=False, download=True, transform=transforms_VAE)\n",
    "\n",
    "VAE_train_dl = DataLoader(VAE_train, batch_size=batch_size, shuffle=True)\n",
    "VAE_test_dl = DataLoader(VAE_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "VAE_dataloaders = {'train': VAE_train_dl, 'val': VAE_test_dl}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
